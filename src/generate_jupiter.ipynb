{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c85c6e24-542e-417a-9565-7471732da3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15231, 1600)\n",
      "File found - Loading from pickle\n",
      "15231\n",
      "torch.Size([6, 4, 5, 5])\n",
      "(15231, 1600)\n",
      "(91386, 4, 5, 5)\n",
      "(91386, 100)\n",
      "['cumdist']\n",
      "torch.Size([15231, 1])\n",
      "['day_of_week']\n",
      "torch.Size([15231, 2])\n",
      "['hour']\n",
      "torch.Size([15231, 2])\n",
      "['month']\n",
      "torch.Size([15231, 2])\n",
      "['timedelta']\n",
      "torch.Size([15231, 1])\n",
      "Continuous conditions:  5\n",
      "Categorical conditions:  3\n",
      "(15231, 8)\n",
      "torch.Size([15231, 8]) torch.Size([15231, 3])\n",
      "Initing with NormalLSR\n",
      "Loading ./artifacts/AirLatDiffTraj_8/best_model.ckpt\n",
      "Model loaded with checkpoint!\n",
      "Trajectory generation model created!\n",
      "torch.Size([8]) torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from typing import Any, Dict\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from lightning.pytorch import Trainer, seed_everything\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from utils import load_config\n",
    "from model.AirDiffTraj import AirDiffTraj, AirDiffTrajDDPM\n",
    "from utils.data_utils import TrafficDataset\n",
    "from traffic.core import Traffic\n",
    "from traffic.algorithms.generation import Generation\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from utils.condition_utils import load_conditions\n",
    "from utils.helper import load_and_prepare_data, get_model\n",
    "from evaluate import get_models, get_config_data\n",
    "import argparse\n",
    "import numpy as np\n",
    "import lightning.pytorch as pl\n",
    "import torch\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "from lightning.pytorch import seed_everything\n",
    "from utils.helper import load_and_prepare_data, get_model, save_config, load_config, init_config, init_model_config, get_model_train\n",
    "from evaluate import get_models,reconstruct_and_plot, plot_traffics, compute_partial_mmd, get_mse_distribution\n",
    "from train import setup_logger, get_dataloaders, train\n",
    "from model.flow_matching import FlowMatching, Wrapper\n",
    "from model.diffusion import Diffusion\n",
    "from evaluation.similarity import compute_energy_distance\n",
    "import os\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from traffic.algorithms.generation import Generation\n",
    "import numpy as np\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import euclidean\n",
    "from evaluation.diversity import data_diversity\n",
    "\n",
    "def local_eval(model, dataset, trajectory_generation_model, n, device)\n",
    "    reconstructions, mse_dict, rnd, fig_0 = reconstruct_and_plot(dataset, model, trajectory_generation_model, n=n, d=device)\n",
    "    plt.show()\n",
    "    fig_smooth = plot_traffics([reconstructions[0],reconstructions[2]])\n",
    "    plt.show()\n",
    "    #n = 10\n",
    "    n_samples = 100\n",
    "    #logger.log_metrics({\"n reconstructions\": n, \"n samples per\" : n_samples})\n",
    "    #length = config['data']['length']\n",
    "\n",
    "    trajectory_generation_model = Generation(\n",
    "        generation=model,\n",
    "        features=dataset.parameters['features'],\n",
    "        scaler=dataset.scaler,\n",
    "    )\n",
    "    \n",
    "    rnd = np.random.randint(0, len(dataset), (n,))\n",
    "    samples = []\n",
    "\n",
    "    for i in tqdm(rnd):\n",
    "        # Load the i-th sample from the dataset\n",
    "        x, con, cat, grid = dataset[i]\n",
    "        # Generate samples and steps using the model\n",
    "        sample = model.sample(x, n_samples = n_samples)\n",
    "        samples.append(sample)\n",
    "\n",
    "\n",
    "    #samples, steps = generate_samples(dataset, model, rnd, n = n_samples, length = length)\n",
    "    detached_samples = detach_to_tensor(samples).reshape(-1, len(dataset.features), length)\n",
    "    decoded = get_traffic_from_tensor(detached_samples, dataset, trajectory_generation_model, rnd)\n",
    "    fig_smooth = plot_traffics([reconstructions[0],reconstructions[2]])\n",
    "    \"\"\"\n",
    "    fig_mse_dict = get_mse_distribution(mse_dict)\n",
    "    #cols = [ 'latitude', 'longitude', 'altitude', 'groundspeed']\n",
    "    cols = [ 'latitude', 'longitude', 'altitude']\n",
    "    subset1_data = reconstructions[0].data[cols].dropna().values\n",
    "    #subset2_data = df_subset2[['latitude', 'longitude']].dropna().values\n",
    "    subset2_data = reconstructions[2].data[cols].dropna().values\n",
    "    #subset2_data = .data.dropna().values\n",
    "\n",
    "    mmd, mmd_std = compute_partial_mmd(reconstructions[0],reconstructions[2] )\n",
    "    # Compute energy distance between the raw trajectories\n",
    "    energy_dist, edist_std = compute_energy_distance(subset1_data, subset2_data)    \n",
    "    dtw, dtw_std, _ = compute_dtw_3d_batch(subset1_data, subset2_data)\n",
    "    fig_pca = data_diversity(subset1_data, subset2_data, 'PCA', 'samples', model_name=model_name)\n",
    "    fig_tsne = data_diversity(subset1_data, subset2_data, 't-SNE', 'samples', model_name = model_name)\n",
    "    logger.experiment.log_figure(logger.run_id, fig_pca, f\"figures/pca.png\")\n",
    "    logger.experiment.log_figure(logger.run_id, fig_tsne, f\"figures/tsne.png\")\n",
    "    \"\"\"\n",
    "\n",
    "checkpoint = f\"artifacts/AirLatFMTraj_norm_landing_4/best_model.ckpt\"\n",
    "config_file = f\"artifacts/AirLatFMTraj_norm_landing_4/config.yaml\"\n",
    "#artifact_location = args.artifact_location\n",
    "#start_model = get_lowest_model_folder(artifact_location, args.model_name)\n",
    "\n",
    "#checkpoint = f\"{artifact_location}/{start_model}/best_model.ckpt\"\n",
    "#config_file = f\"{artifact_location}/{start_model}/config.yaml\"\n",
    "config = load_config(config_file)\n",
    "dataset_config = load_config(\"configs/dataset_landing_transfer.yaml\")\n",
    "#config = init_config(config, dataset_config, args, experiment = \"test\")\n",
    "\n",
    "dataset_config[\"data_path\"] = \"/mnt/data/synthair/synthair_diffusion/data/resampled/combined_traffic_resampled_landing_EGLL_EHAM_LFPG_LSZH_200.pkl\"\n",
    "dataset, traffic = load_and_prepare_data(dataset_config)\n",
    "model_config = init_model_config(config, dataset_config, dataset)\n",
    "\n",
    "print(dataset.data.shape)\n",
    "print(dataset.con_conditions.shape, dataset.cat_conditions.shape)\n",
    "print(\"Dataset loaded!\")\n",
    "print(f\"*******model parameters: {model_config}\")\n",
    "train_config = config[\"train\"]\n",
    "train_config[\"devices\"] = \"cuda:0\"\n",
    "train_config[\"epochs\"] = 100\n",
    "config[\"logger\"][\"experiment_name\"] = \"transfer learning EIDW\"\n",
    "device = torch.device(f\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "n = 1\n",
    "#print(f\"Training with {split} of the dataset...\")\n",
    "config[\"logger\"][\"tags\"]['eval'] = \"True\"\n",
    "#config[\"logger\"][\"tags\"]['pretrained'] = \"False\"\n",
    "#l_logger, run_name, artifact_location = setup_logger(args, config)\n",
    "#l_logger.log_metrics({\"split\": split})\n",
    "\n",
    "#checkpoint = f\"{artifact_location}/{model_name}/best_model.ckpt\"\n",
    "model, trajectory_generation_model = get_models(config['model'], dataset.parameters, checkpoint, dataset.scaler, device)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed437cbd-10de-4f81-849b-8c73b17406d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_eval(model, dataset, trajectory_generation_model, n, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4be2514-c20d-4f88-9db0-915bbb4acca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, con, cat, grid = dataset[:2]\n",
    "x = X.to(\"cuda\")\n",
    "con = con.to(\"cuda\")\n",
    "cat = cat.to(\"cuda\")\n",
    "grid = grid.to(\"cuda\")\n",
    "z = model.vae.get_latent(x, con, cat, grid)\n",
    "x_hat = model.vae.decode(z)\n",
    "nn.functional.mse_loss(x, x_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5cfa8f-5ce4-45a2-9d11-0b9c5c063bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c93dd4f-c00d-4754-b5b6-aef012019018",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [04:00<00:00,  4.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(4.9222e+08, device='cuda:0', grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_hat = z.unsqueeze(1)\n",
    "z_hat, _ = model.generative_model.reconstruct(z_hat, con, cat, grid)\n",
    "z_hat = z_hat.squeeze(1)\n",
    "nn.functional.mse_loss(z, z_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f5b3e32-060b-4c87-bfe7-1433f9d7647d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0079, device='cuda:0', grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = (z.unsqueeze(1), con, cat, grid)\n",
    "loss = model.generative_model.training_step(batch, [])\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ef51b70-573d-4882-a392-212691c7cdd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 601/601 [02:18<00:00,  4.33it/s]\n",
      "/tmp/ipykernel_664814/1408486447.py:20: UserWarning: Using a target size (torch.Size([2, 128])) that is different to the input size (torch.Size([2, 1, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  nn.functional.mse_loss(z_hat, z_hat_2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(13.9968, device='cuda:0', grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(\"diff reconstruct\", x.shape)\n",
    "from tqdm import tqdm\n",
    "steps = []\n",
    "z_hat = z.unsqueeze(1)\n",
    "with torch.no_grad():\n",
    "    #Fix this\n",
    "    #t = torch.tensor([model.generative_model.n_steps-1], device=\"cuda\")\n",
    "    t = torch.tensor([600], device=\"cuda\")\n",
    "    #print(\"t\", t)\n",
    "    x_t, noise = model.generative_model.q_xt_x0(z_hat, t)\n",
    "    #print(z_hat, x_t)\n",
    "    for i in tqdm(range(600, -1, -1)):\n",
    "        x_t = model.generative_model.sample_step_ddim(x_t,con, cat,grid, i)\n",
    "        if i % 200 == 0:\n",
    "            steps.append(x_t.clone().detach())\n",
    "\n",
    "\n",
    "z_hat_2 = x_t.squeeze(1)\n",
    "\n",
    "nn.functional.mse_loss(z_hat, z_hat_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c717a210-52b6-46e0-9323-da8200a1a3cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3692, device='cuda:0', grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_hat = model.vae.decode(z_hat_2)\n",
    "nn.functional.mse_loss(x, x_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "392dbc9f-b9fe-4dc5-a445-5e59b6af5525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 128])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = model.vae.encoder(x)\n",
    "q = model.vae.lsr(h)\n",
    "z = q.rsample([1]).transpose(0, 1)\n",
    "print(z.shape)\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "557bd181-d398-402d-8a78-69b5f70d8ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15231, 1400)\n",
      "File found - Loading from pickle\n",
      "15231\n",
      "torch.Size([6, 4, 5, 5])\n",
      "(15231, 1400)\n",
      "(91386, 4, 5, 5)\n",
      "(91386, 100)\n",
      "['cumdist']\n",
      "torch.Size([15231, 1])\n",
      "['day_of_week']\n",
      "torch.Size([15231, 2])\n",
      "['hour']\n",
      "torch.Size([15231, 2])\n",
      "['month']\n",
      "torch.Size([15231, 2])\n",
      "['timedelta']\n",
      "torch.Size([15231, 1])\n",
      "Continuous conditions:  5\n",
      "Categorical conditions:  3\n",
      "(15231, 8)\n",
      "torch.Size([15231, 8]) torch.Size([15231, 3])\n",
      "Model loaded with checkpoint!\n",
      "Trajectory generation model created!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'reconstruct_and_plot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#logger.log_metrics({\"n reconstructions\": n, \"n samples per\" : n_samples})\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m reconstructions, mse, rnd, fig_0 \u001b[38;5;241m=\u001b[39m \u001b[43mreconstruct_and_plot\u001b[49m(dataset, model, trajectory_generation_model, n\u001b[38;5;241m=\u001b[39mn, model_name \u001b[38;5;241m=\u001b[39m model_name)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#logger.log_metrics({\"Eval_MSE\": mse})\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#ogger.experiment.log_figure(logger.run_id,fig_0, f\"figures/Eval_reconstruction.png\")\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#logger.experiment.log_figure(logger.run_id, fig, \"figures/my_plot.png\")\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#print(reconstructions[1].data)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m JSD, KL, e_distance, fig_1 \u001b[38;5;241m=\u001b[39m jensenshannon_distance(reconstructions[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdata, reconstructions[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdata, model_name \u001b[38;5;241m=\u001b[39m model_name)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reconstruct_and_plot' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "model_name = \"AirDiffTraj_5\"\n",
    "\n",
    "data_path = \"data/resampled/combined_traffic_resampled_200.pkl\"\n",
    "artifact_location= \"./artifacts\"\n",
    "checkpoint = f\"./artifacts/{model_name}/best_model.ckpt\"\n",
    "config_file = f\"./artifacts/{model_name}/config.yaml\"\n",
    "\n",
    "config = load_config(config_file)\n",
    "\n",
    "\n",
    "\n",
    "#logger.experiment.log_dict(logger.run_id,config, config_file)\n",
    "config, dataset, traffic, conditions = get_config_data(config_file, data_path, artifact_location)\n",
    "config['model'][\"traj_length\"] = dataset.parameters['seq_len']\n",
    "config['model'][\"continuous_len\"] = dataset.con_conditions.shape[1]\n",
    "model, trajectory_generation_model = get_models(config[\"model\"], dataset.parameters, checkpoint, dataset.scaler)\n",
    "dataset_config = config[\"data\"]\n",
    "batch_size = dataset_config[\"batch_size\"]\n",
    "n = 100\n",
    "n_samples = 4\n",
    "#logger.log_metrics({\"n reconstructions\": n, \"n samples per\" : n_samples})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0154a836-80a4-4aa1-a96b-8e767ab3804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "n_samples = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e85e9b-c15c-476c-b08a-242e74d0073a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: torch.Size([100, 8]) torch.Size([100, 3]) torch.Size([100, 7, 200])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [06:22<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: tensor(0.1321, device='cuda:0')\n",
      "Data shape: (100, 7, 200)\n",
      "Data shape: (100, 7, 200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy Distance between the two subsets: 3.1823334588443553\n",
      "KL Divergence between the two subsets: 0.22926447335672237\n",
      "Jensen-Shannon Distance between the two subsets: 0.21504481141886125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                    | 88/100 [2:21:50<18:09, 90.79s/it]"
     ]
    }
   ],
   "source": [
    "from evaluate import reconstruct_and_plot\n",
    "from evaluation.diversity import data_diversity\n",
    "from evaluation.similarity import jensenshannon_distance\n",
    "from evaluation.time_series import duration_and_speed, timeseries_plot\n",
    "from evaluate import plot_traffic_comparison, generate_samples\n",
    "reconstructions, mse, rnd, fig_0 = reconstruct_and_plot(dataset, model, trajectory_generation_model, n=n, model_name = model_name, rnd=None)\n",
    "#logger.log_metrics({\"Eval_MSE\": mse})\n",
    "#ogger.experiment.log_figure(logger.run_id,fig_0, f\"figures/Eval_reconstruction.png\")\n",
    "#logger.experiment.log_figure(logger.run_id, fig, \"figures/my_plot.png\")\n",
    "#print(reconstructions[1].data)\n",
    "JSD, KL, e_distance, fig_1 = jensenshannon_distance(reconstructions[0].data, reconstructions[1].data, model_name = model_name)\n",
    "#logger.log_metrics({\"Eval_edistance\": e_distance, \"Eval_JSD\": JSD, \"Eval_KL\": KL})\n",
    "#logger.experiment.log_figure(logger.run_id, fig_1, f\"figures/Eval_comparison.png\")\n",
    "#density(reconstructions, model_name = model_name)\n",
    "fig_landing = plot_traffic_comparison(reconstructions, 2, f\"./figures/{model_name}_\", landing = True)\n",
    "fig_takeoff = plot_traffic_comparison(reconstructions, 2, f\"./figures/{model_name}_\", landing = False)\n",
    "#logger.experiment.log_figure(logger.run_id, fig_landing, f\"figures/landing_comparison.png\")\n",
    "#logger.experiment.log_figure(logger.run_id, fig_takeoff, f\"figures/takeoff_comparison.png\")\n",
    "length = config['data']['length']\n",
    "\n",
    "samples, steps = generate_samples(dataset, model, rnd, n = n_samples, length = length)\n",
    "#fig_99 = get_figure_from_sample_steps(steps, dataset, length)\n",
    "#fig_99.savefig(f\"./figures/{model_name}_generated_steps.png\")\n",
    "#logger.experiment.log_figure(logger.run_id, fig_99, f\"figures/generated_steps.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a946a42-260d-4220-9532-7f59b24397d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(rnd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97153214-7b72-4e65-bad4-4c98cafd6e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import detach_to_tensor\n",
    "detached_samples = detach_to_tensor(samples).reshape(-1, len(dataset.features), length)\n",
    "reco_x = detached_samples.transpose(0, 2, 1).reshape(detached_samples.shape[0], -1)\n",
    "decoded = dataset.scaler.inverse_transform(reco_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8f2272f-207f-46e5-8b15-5b5157ed5f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 1400) torch.Size([10, 7, 200])\n",
      "(40, 200, 2) torch.Size([10, 200, 2])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "def data_diversity(ori_data, generated_data, analysis, average_dimension='sequence', max_sample_size=1000, model_name='model'):\n",
    "    \"\"\"\n",
    "    Data diversity assessment using PCA or t-SNE for original & synthetic distribution visualization.\n",
    "\n",
    "    Inputs:\n",
    "        - ori_data (array): original data\n",
    "        - synthetic_data (array): synthetic data\n",
    "        - analysis_type (str): PCA or t-SNE\n",
    "        - average_dimension (string): flatten along 'sequence' or 'samples' dimension\n",
    "        - max_sample_size (int): maximum sample size for computational speed\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    \n",
    "    # Determine the analysis sample size (minimum of 1000 or the length of the original data)\n",
    "    anal_sample_no = min(max_sample_size, len(ori_data))\n",
    "\n",
    "    # Randomly permute indices for data preprocessing\n",
    "    idx = np.random.permutation(len(ori_data))[:anal_sample_no]\n",
    "\n",
    "    # Convert original and generated data to numpy arrays and select a subset based on indices\n",
    "    ori_data, generated_data = np.asarray(ori_data)[idx], np.asarray(generated_data)[idx]\n",
    "\n",
    "    if average_dimension =='sequence':\n",
    "        # Compute the mean along the sequence length dimension for both datasets\n",
    "        prep_data = np.mean(ori_data[:, :, :], axis=1)\n",
    "        prep_data_hat = np.mean(generated_data[:, :, :], axis=1)\n",
    "    \n",
    "    elif average_dimension =='samples':\n",
    "        prep_data = np.mean(ori_data[:, :, :], axis=2)\n",
    "        prep_data_hat = np.mean(generated_data[:, :, :], axis=2)\n",
    "        \n",
    "    else:\n",
    "        prep_data = ori_data.reshape(ori_data.shape[0], -1)\n",
    "        prep_data_hat = generated_data.reshape(generated_data.shape[0], -1)\n",
    "            \n",
    "    # Define colors for visualization (red for original, blue for synthetic)\n",
    "    colors = [\"red\"] * anal_sample_no + [\"blue\"] * anal_sample_no\n",
    "\n",
    "    # Perform analysis based on user choice (PCA or t-SNE)\n",
    "    if analysis == 'PCA':\n",
    "        # Apply PCA to both original and synthetic data\n",
    "        pca_results = PCA(n_components=2).fit_transform(prep_data)\n",
    "        pca_hat_results = PCA(n_components=2).fit_transform(prep_data_hat)\n",
    "\n",
    "        # Plot PCA results\n",
    "        plt.scatter(pca_results[:, 0], pca_results[:, 1], c=colors[:anal_sample_no], alpha=0.35, label=\"Original\")\n",
    "        plt.scatter(pca_hat_results[:, 0], pca_hat_results[:, 1], c=colors[anal_sample_no:], alpha=0.35, label=\"Synthetic\")\n",
    "\n",
    "    elif analysis == 't-SNE':\n",
    "        # Combine preprocessed data for t-SNE analysis\n",
    "        prep_data_final = np.concatenate((prep_data, prep_data_hat), axis=0)\n",
    "\n",
    "        # Apply t-SNE to combined data\n",
    "        tsne_results = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300).fit_transform(prep_data_final)\n",
    "\n",
    "        # Plot t-SNE results\n",
    "        plt.scatter(tsne_results[:anal_sample_no, 0], tsne_results[:anal_sample_no, 1], c=colors[:anal_sample_no], alpha=0.35, label=\"Original\")\n",
    "        plt.scatter(tsne_results[anal_sample_no:, 0], tsne_results[anal_sample_no:, 1], c=colors[anal_sample_no:], alpha=0.35, label=\"Synthetic\")\n",
    "\n",
    "    # Add legend and labels to the plot\n",
    "    # plt.legend()\n",
    "    plt.title('PCA Plot' if analysis == 'PCA' else 't-SNE Plot')\n",
    "    plt.xlabel('x-pca' if analysis == 'PCA' else 'x-tsne')\n",
    "    plt.ylabel('y-pca' if analysis == 'PCA' else 'y-tsne')\n",
    "    plt.legend()\n",
    "    #plt.savefig(f'./figures/{model_name}_diversity_{analysis}', dpi=400, bbox_inches='tight')\n",
    "    return fig\n",
    "\n",
    "print(decoded.shape, dataset[rnd][0].shape)\n",
    "X = dataset[rnd][0].reshape(-1, length, len(dataset.features))[:,:,:2]\n",
    "X_gen = decoded.reshape(-1, length, len(dataset.features))[:,:,:2]\n",
    "print(X_gen.shape, X.shape)\n",
    "fig_pca = data_diversity(X, X_gen, 'PCA', 'samples', model_name=model_name)\n",
    "#fig_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403b4e2d-aa3c-42c5-b2ef-12f8ad1223f3",
   "metadata": {},
   "source": [
    "# Sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3257bba7-8b06-44d4-b169-6d40b224a7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd = np.random.randint(0, len(dataset), (30))\n",
    "def generate_samples(dataset, model, k=10, n=10, length=200):\n",
    "    # Initialize lists to store results for each sample\n",
    "    all_samples = []\n",
    "    all_steps = []\n",
    "    #print(rnd)\n",
    "    for i in rnd:\n",
    "        # Load the i-th sample from the dataset\n",
    "        x, con, cat, grid = dataset[i]\n",
    "        \n",
    "        # Reshape con and cat as required\n",
    "        con = con.reshape(1, -1)\n",
    "        cat = cat.reshape(1, -1)\n",
    "        \n",
    "        # Adjust the shape of x\n",
    "        #x = x.view(-1, 1, 28, 28)\n",
    "        \n",
    "        # Move grid to the device and adjust dimensions\n",
    "        grid = grid.unsqueeze(dim=0).to(\"cuda\")\n",
    "        \n",
    "        # Generate samples and steps using the model\n",
    "        samples, steps = model.sample(n, con, cat, grid, length)\n",
    "        \n",
    "        # Append results to the lists\n",
    "        all_samples.append(samples)\n",
    "        all_steps.append(steps)\n",
    "        \n",
    "        # Print out shapes for verification (optional)\n",
    "        print(f\"Sample {i+1}:\")\n",
    "        #print(\"cat shape:\", cat.shape)\n",
    "        #print(\"grid shape:\", grid.shape)\n",
    "        #print(\"samples shape:\", samples.shape)\n",
    "        #print(\"steps length:\", len(steps))\n",
    "    \n",
    "    return all_samples, all_steps\n",
    "\n",
    "\n",
    "samples, steps = generate_samples(dataset, model, 30, 100)\n",
    "#print(samples)\n",
    "#print(samples.shape)\n",
    "#print(len(steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d5d71d-f857-4b51-bb57-3a8489080c59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82798845-f348-43e7-a907-15e20c076e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy\n",
    "import traffic.core as tc  # Ensure the traffic library is installed\n",
    "\n",
    "def detach_to_tensor(tensor_list):\n",
    "    \"\"\"\n",
    "    Detaches each tensor in the list, moves to CPU, and stacks them into a single tensor.\n",
    "    \"\"\"\n",
    "    return np.stack([tensor.cpu().detach() for tensor in tensor_list])\n",
    "\n",
    "def plot_from_array(t):\n",
    "    \"\"\"\n",
    "    Plots data from a traffic.core.Traffic object on a EuroPP projection.\n",
    "    \"\"\"\n",
    "    plt.style.use(\"ggplot\")\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "\n",
    "    ax1 = fig.add_subplot(1, 1, 1, projection=ccrs.EuroPP())\n",
    "    ax1.coastlines()\n",
    "    t.plot(ax1, alpha=0.5, color=\"red\", linewidth=1)\n",
    "    ax1.add_feature(cartopy.feature.BORDERS, linestyle=\":\", alpha=1.0)\n",
    "    plt.xlabel('X values')\n",
    "    plt.ylabel('Y values')\n",
    "    plt.title('Plot of X and Y Data from Array')\n",
    "    plt.show()\n",
    "\n",
    "# Assuming 'samples' is a list of tensors generated by model.sample\n",
    "# Detach and stack samples into a single tensor\n",
    "detached_samples = detach_to_tensor(samples).reshape(-1, 4, 200)\n",
    "\n",
    "# Confirm detached_samples is a tensor and ready for use\n",
    "print(\"Detached samples tensor shape:\", detached_samples.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137d8dc0-dd41-421d-b616-93cb1f487c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from traffic.algorithms.generation import Generation\n",
    "\n",
    "trajectory_generation_model = Generation(\n",
    "    generation=model,\n",
    "    features=dataset.parameters['features'],\n",
    "    scaler=dataset.scaler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a16b25-7ed9-46ba-96a7-8fa3b6920660",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reco_x = detached_samples.transpose(0, 2, 1).reshape(detached_samples.shape[0], -1)\n",
    "decoded = dataset.scaler.inverse_transform(reco_x)\n",
    "reconstructed_traf = trajectory_generation_model.build_traffic(\n",
    "    decoded,\n",
    "    coordinates=dict(latitude=48.5, longitude=8.4),\n",
    "    forward=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0037b7-4f32-4913-a225-15a6c477256f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reconstructed_traf\n",
    "plot_from_array(reconstructed_traf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb2f798-67f8-4c42-8af3-afc3a9520c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE \n",
    "from sklearn.decomposition import PCA  \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np  \n",
    "\n",
    "def data_diversity(ori_data, generated_data, analysis, average_dimension='sequence', max_sample_size=1000):\n",
    "    \"\"\"\n",
    "    Data diversity assessment using PCA or t-SNE for original & synthetic distribution visualization.\n",
    "\n",
    "    Inputs:\n",
    "        - ori_data (array): original data\n",
    "        - synthetic_data (array): synthetic data\n",
    "        - analysis_type (str): PCA or t-SNE\n",
    "        - average_dimension (string): flatten along 'sequence' or 'samples' dimension\n",
    "        - max_sample_size (int): maximum sample size for computational speed\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    \n",
    "    # Determine the analysis sample size (minimum of 1000 or the length of the original data)\n",
    "    anal_sample_no = min(max_sample_size, len(ori_data))\n",
    "\n",
    "    # Randomly permute indices for data preprocessing\n",
    "    idx = np.random.permutation(len(ori_data))[:anal_sample_no]\n",
    "\n",
    "    # Convert original and generated data to numpy arrays and select a subset based on indices\n",
    "    ori_data, generated_data = np.asarray(ori_data)[idx], np.asarray(generated_data)[idx]\n",
    "\n",
    "    if average_dimension =='sequence':\n",
    "        # Compute the mean along the sequence length dimension for both datasets\n",
    "        prep_data = np.mean(ori_data[:, :, :], axis=1)\n",
    "        prep_data_hat = np.mean(generated_data[:, :, :], axis=1)\n",
    "    \n",
    "    elif average_dimension =='samples':\n",
    "        prep_data = np.mean(ori_data[:, :, :], axis=2)\n",
    "        prep_data_hat = np.mean(generated_data[:, :, :], axis=2)\n",
    "        \n",
    "    else:\n",
    "        prep_data = ori_data.reshape(ori_data.shape[0], -1)\n",
    "        prep_data_hat = generated_data.reshape(generated_data.shape[0], -1)\n",
    "            \n",
    "    # Define colors for visualization (red for original, blue for synthetic)\n",
    "    colors = [\"red\"] * anal_sample_no + [\"blue\"] * anal_sample_no\n",
    "\n",
    "    # Perform analysis based on user choice (PCA or t-SNE)\n",
    "    if analysis == 'PCA':\n",
    "        # Apply PCA to both original and synthetic data\n",
    "        pca_results = PCA(n_components=2).fit_transform(prep_data)\n",
    "        pca_hat_results = PCA(n_components=2).fit_transform(prep_data_hat)\n",
    "\n",
    "        # Plot PCA results\n",
    "        plt.scatter(pca_results[:, 0], pca_results[:, 1], c=colors[:anal_sample_no], alpha=0.35, label=\"Original\")\n",
    "        plt.scatter(pca_hat_results[:, 0], pca_hat_results[:, 1], c=colors[anal_sample_no:], alpha=0.35, label=\"Synthetic\")\n",
    "\n",
    "    elif analysis == 't-SNE':\n",
    "        # Combine preprocessed data for t-SNE analysis\n",
    "        prep_data_final = np.concatenate((prep_data, prep_data_hat), axis=0)\n",
    "\n",
    "        # Apply t-SNE to combined data\n",
    "        tsne_results = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300).fit_transform(prep_data_final)\n",
    "\n",
    "        # Plot t-SNE results\n",
    "        plt.scatter(tsne_results[:anal_sample_no, 0], tsne_results[:anal_sample_no, 1], c=colors[:anal_sample_no], alpha=0.35, label=\"Original\")\n",
    "        plt.scatter(tsne_results[anal_sample_no:, 0], tsne_results[anal_sample_no:, 1], c=colors[anal_sample_no:], alpha=0.35, label=\"Synthetic\")\n",
    "\n",
    "    # Add legend and labels to the plot\n",
    "    # plt.legend()\n",
    "    plt.title('PCA Plot' if analysis == 'PCA' else 't-SNE Plot')\n",
    "    plt.xlabel('x-pca' if analysis == 'PCA' else 'x-tsne')\n",
    "    plt.ylabel('y-pca' if analysis == 'PCA' else 'y-tsne')\n",
    "    plt.savefig('diversity', dpi=400, bbox_inches='tight')\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "print(decoded.shape)\n",
    "data_diversity(dataset[:3000][0][:,:2,:], reco_x.reshape(3000, 4, 200)[:,:2,:], 'PCA', 'sequence')\n",
    "data_diversity(dataset[:3000][0][:,:2,:], reco_x.reshape(3000, 4, 200)[:,:2,:], 'PCA', 'samples')\n",
    "data_diversity(dataset[:3000][0][:,:2,:], reco_x.reshape(3000, 4, 200)[:,:2,:], 'PCA')\n",
    "data_diversity(dataset[:3000][0][:,:2,:], reco_x.reshape(3000, 4, 200)[:,:2,:], 't-SNE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d527f097-3316-4e52-8af1-8c852181a1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def plot_from_array(data):\n",
    "    # Check if the input data has the correct shape\n",
    "    #if data.shape[1] != 2:\n",
    "     #   raise ValueError(\"The second dimension of the array must have a size of 2 for x and y coordinates.\")\n",
    "    \n",
    "  # Length of each x and y data series\n",
    "    n = data.shape[0]\n",
    "    plt.style.use(\"ggplot\")\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "    for i in range(n):\n",
    "        y = data[i, :, 0]  # Extract the x values for the i-th series\n",
    "        x = data[i, :, 1]  # Extract the y values for the i-th series\n",
    "        \n",
    "        plt.scatter(x, y, label=f'Series {i+1}')  # Plot each series with a label\n",
    "\n",
    "    #ax1 = fig.add_subplot(1, 1, 1)\n",
    "    #ax1.coastlines()\n",
    "    #t.plot(ax1, alpha=0.1, color=\"red\", linewidth=0.2)\n",
    "    #ax1.add_feature(cartopy.feature.BORDERS, linestyle=\":\", alpha=1.0)\n",
    "    plt.xlabel('X values')\n",
    "    plt.ylabel('Y values')\n",
    "    plt.title('Plot of X and Y Data from Array')\n",
    "    plt.show()\n",
    "    \n",
    "scaler = dataset.scaler\n",
    "#print(detached_s.shape)\n",
    "\n",
    "detached_w = detached_s.transpose(0, 2, 1).reshape(detached_s.shape[0], -1)\n",
    "detached_w = scaler.inverse_transform(detached_w).reshape(100, -1, 4)\n",
    "\n",
    "\n",
    "print(detached_w.shape)\n",
    "\n",
    "plot_from_array(detached_w[:1, :, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20899bcc-4b77-4f61-a0e0-537fa76d32eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"for i in steps:\n",
    "    scaler = dataset.scaler\n",
    "    i = i.cpu().numpy()\n",
    "    #print(detached_s.shape)\n",
    "    detached_w = i.transpose(0, 2, 1).reshape(i.shape[0], -1)\n",
    "    detached_w = scaler.inverse_transform(detached_w).reshape(100, -1, 4)\n",
    "    #print(detached_w.shape)\n",
    "    \n",
    "    plot_from_array(detached_w[:, :, :2])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ed548b-6254-40f8-9f0d-77e0137e099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy\n",
    "import traffic.core as tc\n",
    "def plot_diffusion_steps(steps):\n",
    "    \"\"\"\n",
    "    Plot images stored in a list side-by-side to visualize diffusion steps.\n",
    "    \n",
    "    Args:\n",
    "        images (list): A list of images (each can be a 2D numpy array or a tensor) to be plotted.\n",
    "    \"\"\"\n",
    "    n = len(steps)  # Number of images (or steps) in the diffusion process\n",
    "    \n",
    "    # Create subplots with 1 row and n columns\n",
    "    fig, axes = plt.subplots(1, n, figsize=(20, 10))\n",
    "    \n",
    "    # If only one image is provided, make sure axes is iterable\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    # Plot each image in a subplot\n",
    "    scaler = dataset.scaler\n",
    "    for e, i in enumerate(steps):\n",
    "        i = i.cpu().numpy()    \n",
    "        detached_w = i.transpose(0, 2, 1).reshape(i.shape[0], -1)\n",
    "        detached_w = scaler.inverse_transform(detached_w).reshape(i.shape[0], -1, 4)\n",
    "        for p in range(n):\n",
    "            y = detached_w[p, :, 0]  # Extract the x values for the i-th series\n",
    "            x = detached_w[p, :, 1]  # Extract the y values for the i-th series\n",
    "            axes[e].scatter(x, y, label=f'Series {i+1}')  # Plot each series with a label\n",
    "            axes[e].axis('off')  # Turn off the axis for clarity\n",
    "            axes[e].set_title(f\"Step {i+1}\")\n",
    "    \n",
    "    # Adjust the spacing between plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_diffusion_steps(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174cfb9c-58c6-4a21-b959-cbc3e5e0c589",
   "metadata": {},
   "source": [
    "# Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485144ea-bc2c-46a0-88fd-c8dd33b3fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "rnd = np.random.randint(0, len(dataset), (n))\n",
    "X2, con, cat, grid = dataset[rnd]\n",
    "grid = grid.to(\"cuda\")\n",
    "X_ = X2.reshape(n, 4, -1).to(\"cuda\")\n",
    "con_ = con.reshape(n, -1)\n",
    "cat_ = cat.reshape(n, -1)\n",
    "print(con.shape, cat.shape, X_.shape)\n",
    "#model.unet.guidance_scale = 3\n",
    "x_rec, steps = model.reconstruct(X_, con_, cat_, grid)\n",
    "#print(cat.unique(), con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e8d1df-eac7-43d2-989d-fab1fd911e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_.shape, x_rec.shape)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy\n",
    "import traffic.core as tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684e4250-74ad-43e9-ae08-9f36e3314c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax1 = fig.add_subplot(1, 1, 1, projection=ccrs.EuroPP())\n",
    "ax1.coastlines()\n",
    "ax1.add_feature(cartopy.feature.BORDERS, linestyle=\":\", alpha=1.0)\n",
    "plt.xlabel('X values')\n",
    "plt.ylabel('Y values')\n",
    "plt.title('Plot of X and Y Data from Array')\n",
    "print(\"MSE\",torch.nn.functional.mse_loss(X_, x_rec))\n",
    "color = [\"red\", \"blue\"]\n",
    "a = []\n",
    "for c, i in enumerate([X_, x_rec]):\n",
    "    print(i.cpu().numpy().shape)\n",
    "    i = i.cpu().numpy()\n",
    "    reco_x = i.transpose(0, 2, 1).reshape(i.shape[0], -1)\n",
    "    decoded = dataset.scaler.inverse_transform(reco_x)\n",
    "    reconstructed_traf = trajectory_generation_model.build_traffic(\n",
    "    decoded.reshape(n, -1, 4),\n",
    "    coordinates=dict(latitude=48.5, longitude=8.4),\n",
    "    forward=False,\n",
    "    )\n",
    "    a.append(reconstructed_traf)\n",
    "    #for i in range(n):\n",
    "        #x = data[i, 0, :]  # Extract the x values for the i-th series\n",
    "        #y = data[i, 1, :]  # Extract the y values for the i-th series\n",
    "        \n",
    "        #plt.scatter(x, y, label=f'Series {i+1}')  # Plot each series with a label\n",
    "\n",
    "\n",
    "    reconstructed_traf.plot(ax1, alpha=0.5, color=color[c], linewidth=1)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1f2843-d7cb-4eb1-b65b-72965da18340",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj1 = X_.cpu()  # Shape (length, features)\n",
    "traj2 = x_rec.cpu()  # Shape (length, features)\n",
    "\n",
    "# Compute differences (could be absolute difference or any other metric)\n",
    "differences = torch.abs(traj1 - traj2).mean(dim=1)  # Shape (length, features)\n",
    "differences_max, _ = torch.abs(traj1 - traj2).max(dim=1)\n",
    "differences_min, _ = torch.abs(traj1 - traj2).min(dim=1) \n",
    "print(differences.shape)\n",
    "# Plot the differences for each feature over the length of the trajectory\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i in range(3):\n",
    "    name = [\"longitude\", \"latitude\", \"altitude\"]\n",
    "    plt.plot(differences[i, :].numpy(), label=f'{name[i]}')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.title('Feature-wise comparison between two trajectories MEAN')\n",
    "plt.ylabel('Difference')\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i in range(3):\n",
    "    name = [\"longitude\", \"latitude\", \"altitude\"]\n",
    "    plt.plot(differences_max[i, :].numpy(), label=f'{name[i]}')\n",
    "    #plt.plot(differences_min[i, :].numpy(), label=f'{name[i]}')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.title('Feature-wise comparison between two trajectories MAX')\n",
    "plt.ylabel('Difference')\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7c5ace-58ff-4058-882d-76665866f123",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "## Density Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792deb59-c509-44a6-9ba8-c9e928c7872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from traffic.core import Traffic\n",
    "training_trajectories_path = \"./data/resampled/combined_traffic_resampled_200.pkl\"\n",
    "training_trajectories = Traffic.from_file(training_trajectories_path)\n",
    "#synthetic_trajectories_path = \"../data/synthetic_compare/OpenSky_EHAM_LIMC.pkl\"\n",
    "#synthetic_trajectories = Traffic.from_file(synthetic_trajectories_path)\n",
    "synthetic_trajectories = a[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd1edb7-9613-4752-9609-b0a2dabe5bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyproj import Geod\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "def get_flight_durations(traffic):\n",
    "    durations = []\n",
    "    for flight in traffic:\n",
    "        duration = (flight.data['timestamp'].max() - flight.data['timestamp'].min()).total_seconds() / 60  # in minutes\n",
    "        durations.append(duration)\n",
    "    return np.array(durations)\n",
    "\n",
    "def get_flight_speeds(traffic, method='calculate', remove_outliers=True, lower_quantile=0.01, upper_quantile=0.99):\n",
    "    all_speeds = []\n",
    "    geod = Geod(ellps=\"WGS84\")\n",
    "    \n",
    "    for flight in traffic:\n",
    "        if method == 'groundspeed' and 'groundspeed' in flight.data.columns:\n",
    "            speeds = flight.data['groundspeed'].values\n",
    "        elif method == 'calculate':\n",
    "            coords = np.column_stack((flight.data['longitude'], flight.data['latitude']))\n",
    "            times = flight.data['timestamp'].values\n",
    "            \n",
    "            distances = geod.inv(coords[:-1, 0], coords[:-1, 1], coords[1:, 0], coords[1:, 1])[2]\n",
    "            time_diffs = np.diff(times).astype('timedelta64[s]').astype(float)\n",
    "            \n",
    "            # Filter out invalid or negative time differences\n",
    "            valid_mask = (time_diffs > 0) & (distances >= 0)\n",
    "            valid_distances = distances[valid_mask]\n",
    "            valid_time_diffs = time_diffs[valid_mask]\n",
    "            \n",
    "            # Calculate speeds and convert to km/h\n",
    "            speeds = valid_distances / valid_time_diffs * 3.6  \n",
    "        else:\n",
    "            raise ValueError(\"Method must be either 'groundspeed' or 'calculate'\")\n",
    "        \n",
    "        # Remove zero speeds\n",
    "        speeds = speeds[speeds > 0]\n",
    "        \n",
    "        all_speeds.extend(speeds)\n",
    "    \n",
    "    all_speeds = np.array(all_speeds)\n",
    "    if remove_outliers:\n",
    "        lower_bound = np.quantile(all_speeds, lower_quantile)\n",
    "        upper_bound = np.quantile(all_speeds, upper_quantile)\n",
    "        all_speeds = all_speeds[(all_speeds >= lower_bound) & (all_speeds <= upper_bound)]\n",
    "    \n",
    "    return all_speeds\n",
    "\n",
    "training_durations = get_flight_durations(training_trajectories)\n",
    "synthetic_durations = get_flight_durations(synthetic_trajectories)\n",
    "print(training_trajectories)\n",
    "print(training_trajectories[rnd])\n",
    "\n",
    "small_training_trajectories = a[0]\n",
    "small_synthetic_trajectories = a[1]\n",
    "\n",
    "training_speeds = get_flight_speeds(small_training_trajectories, method='calculate')\n",
    "synthetic_speeds = get_flight_speeds(small_synthetic_trajectories, method='calculate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579a311b-5623-41a6-b703-c3f98a18ca02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# Suppress specific UserWarnings related to set_xticklabels\n",
    "warnings.filterwarnings(\"ignore\", message=\".*set_ticklabels.*\")\n",
    "\n",
    "# Set the style for a more professional look\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "# Create a single figure with two rows and two columns\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Row 1: Flight Durations\n",
    "sns.histplot(training_durations, kde=True, element=\"step\", label='Real', color='#1f77b4', linewidth=1.5, ax=axes[0, 0])\n",
    "sns.histplot(synthetic_durations, kde=True, element=\"step\", label='Synthetic', color='#ff7f0e', linewidth=1.5, ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Flight Durations', fontsize=10)\n",
    "axes[0, 0].set_xlabel('Duration (minutes)', fontsize=8)\n",
    "axes[0, 0].set_ylabel('Density', fontsize=8)\n",
    "axes[0, 0].legend(fontsize=6)\n",
    "axes[0, 0].tick_params(labelsize=6)\n",
    "\n",
    "sns.boxplot(data=[training_durations, synthetic_durations], palette=['#1f77b4', '#ff7f0e'], ax=axes[0, 1])\n",
    "axes[0, 1].set_xticklabels(['Real', 'Synthetic'], fontsize=8)\n",
    "axes[0, 1].set_title('Flight Durations', fontsize=10)\n",
    "axes[0, 1].set_ylabel('Duration (minutes)', fontsize=8)\n",
    "axes[0, 1].tick_params(labelsize=6)\n",
    "\n",
    "# Row 2: Flight Speeds\n",
    "sns.histplot(training_speeds, kde=True, element=\"step\", label='Real', color='#1f77b4', linewidth=1.5, ax=axes[1, 0])\n",
    "sns.histplot(synthetic_speeds, kde=True, element=\"step\", label='Synthetic', color='#ff7f0e', linewidth=1.5, ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Flight Speeds', fontsize=10)\n",
    "axes[1, 0].set_xlabel('Speed (km/h)', fontsize=8)\n",
    "axes[1, 0].set_ylabel('Density', fontsize=8)\n",
    "axes[1, 0].legend(fontsize=6)\n",
    "axes[1, 0].tick_params(labelsize=6)\n",
    "\n",
    "sns.boxplot(data=[training_speeds, synthetic_speeds], palette=['#1f77b4', '#ff7f0e'], ax=axes[1, 1])\n",
    "axes[1, 1].set_xticklabels(['Real', 'Synthetic'], fontsize=8)\n",
    "axes[1, 1].set_title('Flight Speeds', fontsize=10)\n",
    "axes[1, 1].set_ylabel('Speed (km/h)', fontsize=8)\n",
    "axes[1, 1].tick_params(labelsize=6)\n",
    "\n",
    "# Adjust layout and remove top and right spines\n",
    "plt.tight_layout()\n",
    "for ax in axes.flatten():\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Add a main title for the entire figure\n",
    "# fig.suptitle('Comparison of Real and Synthetic Flight Data', fontsize=12, y=1.02)\n",
    "\n",
    "# Save the figure\n",
    "#plt.savefig(f\"../.figures/distribution_plots_{route_name}.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5075e5ce-4a83-410b-890a-4f5426460697",
   "metadata": {},
   "source": [
    "## Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67322b81-b60b-40d6-98ba-090fe5cb5946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "def timeseries_plot(\n",
    "    real_traffic,\n",
    "    synthetic_traffic,\n",
    "    features: list,\n",
    "    units: dict,\n",
    "    n_plot_samples: int = 1000,\n",
    "    alpha: float = 0.3\n",
    "):\n",
    "    # Set the style for a more professional look\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    sns.set_context(\"paper\")\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(2, len(features), figsize=(4 * len(features), 6), sharex=True)\n",
    "\n",
    "    # Prepare data\n",
    "    datasets = [real_traffic, synthetic_traffic]\n",
    "    dataset_names = ['Real', 'Synthetic']\n",
    "    colors = ['#1f77b4', '#ff7f0e']  # Specified colors\n",
    "\n",
    "    for feature_idx, feature in enumerate(features):\n",
    "        # Top row: individual trajectories\n",
    "        for dataset_idx, (dataset, color) in enumerate(zip(datasets, colors)):\n",
    "            feature_data = np.array([flight.data[feature].values for flight in dataset])\n",
    "            sample_ind = np.random.randint(0, len(feature_data), min(n_plot_samples, len(feature_data)))\n",
    "            for idx in sample_ind:\n",
    "                axes[0, feature_idx].plot(feature_data[idx], alpha=alpha, color=color)\n",
    "\n",
    "        axes[0, feature_idx].set_title(f\"{feature.capitalize()}\", fontsize=12)\n",
    "        axes[0, feature_idx].tick_params(labelsize=10)\n",
    "        axes[0, feature_idx].set_ylabel(f\"{feature.capitalize()} ({units[feature]})\", fontsize=12)\n",
    "\n",
    "        # Bottom row: mean and confidence intervals\n",
    "        for dataset_idx, (dataset, color) in enumerate(zip(datasets, colors)):\n",
    "            feature_data = np.array([flight.data[feature].values for flight in dataset])\n",
    "            mean_data = np.mean(feature_data, axis=0)\n",
    "            std_data = np.std(feature_data, axis=0)\n",
    "\n",
    "            axes[1, feature_idx].plot(mean_data, color=color, linewidth=2)\n",
    "\n",
    "            t_value = stats.t.ppf(0.975, df=len(feature_data)-1)\n",
    "            ci = t_value * std_data * np.sqrt(1 + 1/len(feature_data))\n",
    "            axes[1, feature_idx].fill_between(\n",
    "                range(len(mean_data)),\n",
    "                mean_data - ci,\n",
    "                mean_data + ci,\n",
    "                color=color,\n",
    "                alpha=0.2\n",
    "            )\n",
    "\n",
    "        axes[1, feature_idx].set_xlabel(\"Time Steps\", fontsize=12)\n",
    "        axes[1, feature_idx].set_ylabel(f\"{feature.capitalize()} ({units[feature]})\", fontsize=12)\n",
    "        axes[1, feature_idx].tick_params(labelsize=10)\n",
    "\n",
    "        # Remove top and right spines for both rows\n",
    "        for row in range(2):\n",
    "            axes[row, feature_idx].spines['top'].set_visible(False)\n",
    "            axes[row, feature_idx].spines['right'].set_visible(False)\n",
    "\n",
    "    # Create custom legend elements\n",
    "    legend_elements = []\n",
    "    for color, name in zip(colors, dataset_names):\n",
    "        legend_elements.append(plt.Line2D([0], [0], color=color, lw=3, label=f'{name}'))\n",
    "        legend_elements.append(Patch(facecolor=color, edgecolor=color, alpha=alpha, label=f'{name} 95% CI'))\n",
    "\n",
    "    # Add a single legend for the entire figure\n",
    "    fig.legend(handles=legend_elements, loc='upper center', ncol=2, fontsize=12, bbox_to_anchor=(0.5, 1.05))\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    #plt.savefig(f\"../.figures/timeseries_ci_{route_name}.png\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Usage\n",
    "features_to_plot = ['latitude', 'longitude', 'altitude', 'timedelta']\n",
    "units = {\n",
    "    'latitude': '°',\n",
    "    'longitude': '°',\n",
    "    'altitude': 'ft',\n",
    "    'timedelta': 's'\n",
    "}\n",
    "\n",
    "timeseries_plot(\n",
    "    training_trajectories,\n",
    "    synthetic_trajectories,\n",
    "    features=features_to_plot,\n",
    "    units=units\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767223c3-a595-484d-88b0-fbb14318d387",
   "metadata": {},
   "source": [
    "## Jensen-Shannon Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0853a58d-b6cb-4128-8980-eb1525d021ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.special import rel_entr\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df_2 is a traffic.core.Traffic object containing trajectories\n",
    "# Split the traffic object into two halves based on a criterion\n",
    "df_subset1 = a[0]\n",
    "df_subset2 = a[1]\n",
    "\n",
    "# Convert the first subset to a DataFrame and extract lat/lon\n",
    "subset1_data = df_subset1.data[['latitude', 'longitude']].dropna().values\n",
    "subset2_data = df_subset2.data[['latitude', 'longitude']].dropna().values\n",
    "\n",
    "# Kernel Density Estimation (KDE) for both subsets\n",
    "kde_subset1 = gaussian_kde(subset1_data.T)\n",
    "kde_subset2 = gaussian_kde(subset2_data.T)\n",
    "\n",
    "# Create grid to evaluate KDEs over a common region (latitude, longitude)\n",
    "xgrid, ygrid = np.mgrid[\n",
    "    min(subset1_data[:, 0].min(), subset2_data[:, 0].min()):max(subset1_data[:, 0].max(), subset2_data[:, 0].max()):100j,\n",
    "    min(subset1_data[:, 1].min(), subset2_data[:, 1].min()):max(subset1_data[:, 1].max(), subset2_data[:, 1].max()):100j\n",
    "]\n",
    "\n",
    "grid_coords = np.vstack([xgrid.ravel(), ygrid.ravel()])\n",
    "\n",
    "# Evaluate the KDEs on the grid\n",
    "subset1_density = kde_subset1(grid_coords).reshape(100, 100)\n",
    "subset2_density = kde_subset2(grid_coords).reshape(100, 100)\n",
    "\n",
    "# Normalize densities to ensure they sum to 1 (turn them into probabilities)\n",
    "subset1_density /= np.sum(subset1_density)\n",
    "subset2_density /= np.sum(subset2_density)\n",
    "\n",
    "# Add a small constant to avoid zeros in the densities\n",
    "epsilon = 1e-10\n",
    "subset1_density += epsilon\n",
    "subset2_density += epsilon\n",
    "\n",
    "# Compute the average distribution M\n",
    "M = 0.5 * (subset1_density + subset2_density)\n",
    "\n",
    "# Calculate Jensen-Shannon distance using the scipy.spatial.distance.jensenshannon method\n",
    "js_distance = jensenshannon(subset1_density.ravel(), subset2_density.ravel(), base=2)\n",
    "kl_divergence = np.sum(rel_entr(subset1_density, subset2_density))\n",
    "\n",
    "print(f\"KL Divergence between the two subsets: {kl_divergence}\")\n",
    "\n",
    "print(f\"Jensen-Shannon Distance between the two subsets: {js_distance}\")\n",
    "\n",
    "# Plotting the KDEs for comparison\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "ax[0].imshow(subset1_density, origin='lower', cmap='Blues', extent=[xgrid.min(), xgrid.max(), ygrid.min(), ygrid.max()])\n",
    "ax[0].set_title(\"Subset 1 Density\")\n",
    "\n",
    "ax[1].imshow(subset2_density, origin='lower', cmap='Reds', extent=[xgrid.min(), xgrid.max(), ygrid.min(), ygrid.max()])\n",
    "ax[1].set_title(\"Subset 2 Density\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf52e36-8ef2-4fcb-8553-c81fa496b9a7",
   "metadata": {},
   "source": [
    "# Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1b82d5-aecb-4043-b92b-0e239eb97b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "from cartopy.crs import EuroPP, PlateCarree\n",
    "from cartes.utils.features import countries, ocean\n",
    "\n",
    "\n",
    "with plt.style.context(\"traffic\"):\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 10), frameon=False)\n",
    "    ax = fig.subplots(1, 2, subplot_kw=dict(projection=EuroPP()))\n",
    "\n",
    "    for ax_ in ax:\n",
    "        ax_.add_feature(countries(scale=\"10m\", linewidth=1.5))\n",
    "\n",
    "    vmax = None  # this trick will keep the same colorbar scale for both maps\n",
    "\n",
    "    for i, data in enumerate([df_subset1, df_subset2]):\n",
    "        # Aggregate and query the data, then convert to xarray\n",
    "        data_xarray = data.agg_latlon(\n",
    "            # 10 points per integer lat/lon\n",
    "            resolution=dict(latitude=10, longitude=10),\n",
    "            # count the number of flights\n",
    "            flight_id=\"nunique\"\n",
    "        ).query(f\"flight_id > 1\").to_xarray()\n",
    "\n",
    "        # Sort the DataArray by latitude and longitude\n",
    "        data_xarray = data_xarray.sortby(['latitude', 'longitude'])\n",
    "\n",
    "        # Plot the data using pcolormesh\n",
    "        cax = data_xarray.flight_id.plot.pcolormesh(\n",
    "            ax=ax[i],\n",
    "            cmap=\"viridis\",\n",
    "            transform=PlateCarree(),\n",
    "            vmax=vmax,\n",
    "            add_colorbar=False,\n",
    "        )\n",
    "\n",
    "        cbaxes = inset_axes(ax[i], \"4%\", \"60%\", loc=3)\n",
    "        cb = fig.colorbar(cax, cax=cbaxes)\n",
    "\n",
    "        # Keep this value to scale the colorbar for the second day\n",
    "        vmax = cb.vmax\n",
    "\n",
    "        text = AnchoredText(\n",
    "            f\"{data.start_time:%B %d, %Y}\",\n",
    "            loc=1,\n",
    "            prop={\"size\": 24, \"fontname\": \"Ubuntu\"},\n",
    "            frameon=True,\n",
    "        )\n",
    "        text.patch.set_boxstyle(\"round,pad=0.,rounding_size=0.2\")\n",
    "        ax[i].add_artist(text)\n",
    "\n",
    "    fig.set_tight_layout(True)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dba248-a42e-45fa-9c11-825ea4b64654",
   "metadata": {},
   "source": [
    "## Length Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcc7186-c310-43af-9b54-bfc3762b1fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import geodesic\n",
    "\n",
    "def haversine(lat1, lon1,alt1, lat2, lon2, alt2):\n",
    "    \"\"\"\n",
    "    Compute the great-circle distance between two points on the Earth's surface using their lat/lon values.\n",
    "    Uses the geodesic method from the geopy library, which accounts for Earth's shape.\n",
    "    \n",
    "    Parameters:\n",
    "    - lat1, lon1: Latitude and longitude of the first point\n",
    "    - lat2, lon2: Latitude and longitude of the second point\n",
    "    \n",
    "    Returns:\n",
    "    - Distance between the two points in meters.\n",
    "    \"\"\"\n",
    "    return geodesic((lat1, lon1, alt1), (lat2, lon2, alt2)).meters\n",
    "\n",
    "\n",
    "n = 100\n",
    "X2, con, cat = dataset[:n]\n",
    "X_ = X2.reshape(n, 4, -1).to(\"cuda\")\n",
    "con_ = con.reshape(n, -1)\n",
    "cat_ = cat.reshape(n, -1)\n",
    "print(con.shape, cat.shape, X_.shape)\n",
    "model.unet.guidance_scale = 20\n",
    "x_rec, steps = model.reconstruct(X_, con_, cat_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64766ffa-0601-4d47-907f-b65f3311f1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(X):\n",
    "    x_rec = X.cpu().numpy()\n",
    "    reco_x = x_rec.transpose(0, 2, 1).reshape(X.shape[0], -1)\n",
    "    decoded = dataset.scaler.inverse_transform(reco_x)\n",
    "    reconstructed_traf = trajectory_generation_model.build_traffic(\n",
    "    decoded.reshape(n, -1, 4),\n",
    "    coordinates=dict(latitude=48.5, longitude=8.4),\n",
    "    forward=False,\n",
    "    )\n",
    "    return reconstructed_traf\n",
    "X_ = build(X_)\n",
    "x_rec = build(x_rec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
